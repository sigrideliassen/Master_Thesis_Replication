library(data.table)
library(zoo)
library(dplyr)

library(scales)     # for nicer axes of figures
library(viridis)    # for nicer colors in figures
library(vroom)      # for fast csv reading

#============================================================================
#============================================================================
#============================================================================

# IMPORT CRSP DATA # 
library(readxl)
NYSE = as.data.table(read_excel("Documents/Master/Master Thesis/Data_CRSP_Compustat/NYSE.xlsx"))
AMEX = as.data.table(read_excel("Documents/Master/Master Thesis/Data_CRSP_Compustat/AMEX.xlsx"))
NASDAQ = as.data.table(read_excel("Documents/Master/Master Thesis/Data_CRSP_Compustat/NASDAQ.xlsx"))

# MERGE DATA # 
data = merge(NYSE, AMEX, all = TRUE)
data = merge(data, NASDAQ, all = TRUE)
rm(AMEX, NYSE, NASDAQ)

#============================================================================
#============================================================================
#============================================================================

# CLEANING # 
data$RET = as.numeric(data$RET)*100
data$DLRET = as.numeric(data$DLRET)*100
data$DATE = as.Date(data$DATE)
data$PRC = abs(data$PRC) 

# Replace NA returns with delisted returns # 
index = which(!is.na(data$DLRET))
D_R = data$DLRET[index]
R = data$RET
R[R = index] <- D_R
data$RET = R 

data = data[-which(is.na(data$SHROUT))]

# Replace NA prices calculated from delisted returns # 
index = which(!is.na(data$DLRET))
P = data$PRC
P[P=index] <- P[index - 1]*(1 + data$RET[index])
data$PRC = P 

# NA prices and returns without delisting returns - DELETING ROWS # 
data = data[-which(is.na(data$PRC))]
data = data[-which(is.na(data$RET))]

#============================================================================
#============================================================================
#============================================================================

# FINDING MARKET CAP 
data$MKTCAP = data[,MKTCAP:=abs(PRC)*SHROUT]

# Sort by PERMNO 
setkey(data,PERMNO,DATE)
vec=c('PERMNO','DATE')
setorderv(data,vec) 

# CREATE LAGGED MARKET CAP OF EACH STOCK AT EACH DATE 
# data$MKTCAP_LAG = data[,MKTCAP_LAG:=shift(MKTCAP), by=PERMNO]

#============================================================================
#============================================================================
#============================================================================

data[,Year:=year(DATE)]
data[,month:=month(DATE)]
data[,key:=paste(Year,month)]

# Remove NA and redundant data # 
data = data[,SHRCD:=NULL]
data = data[,DLRET:=NULL]
data = data[,PRC:=NULL]
data = data[,SHROUT:=NULL]
data = na.omit(data)

#============================================================================
#============================================================================
#============================================================================

# Aggregate return of firm that has several securities traded
# data[,PERMNO_weight:=MKTCAP_LAG/sum(MKTCAP_LAG)]
# data[,RET_W:=sum(PERMNO_weight*RET),by=.(PERMCO,key)]
# data[,MKTCAP_LAG:=sum(MKTCAP_LAG),by=.(PERMCO,key)]
# data=unique(data[,.(PERMNO,DATE,EXCHCD,MKTCAP,MKTCAP_LAG,RET,RET_W,key,Year,month,PERMCO,PERMNO_weight)],by=c("PERMCO","key"))
# setorder(data,PERMCO,key) 

#============================================================================
#============================================================================
#============================================================================

# LINKING TABLE #  
link = as.data.table(read_excel("Documents/Master/Master Thesis/Data_CRSP_Compustat/link.xlsx"))
link$LINKDT = as.Date(link$LINKDT,format="%Y%m%d")
link$LINKENDDT = as.Date(link$LINKENDDT,format="%Y%m%d")

merged = merge(data,link,by.x ="PERMCO",by.y ="LPERMCO",allow.cartesian = T)
setkey(merged)
merged = merged[(is.na(LINKDT) | merged$DATE>=merged$LINKDT) & (is.na(LINKENDDT) | DATE<=LINKENDDT)]
setorder(merged,GVKEY,DATE)

merged = merged[,LPERMNO:=NULL]
merged = merged[,LINKTYPE:=NULL]

#============================================================================
#============================================================================
#============================================================================

# Multiple GVKEYS per PERMCO # 

# FIRST # 
# If 01 and not 01 LIID # 
merged[,prob:=.N>1,by=.(PERMCO,DATE)]
merged[,Good_match:=sum(LIID==01),by=.(PERMCO,DATE)]
merged = merged[!(prob==TRUE & Good_match==TRUE & LIID!=01)]

# SECOND # 
# Use the link that's current # 
merged[,prob:=.N>1,by=.(PERMCO,DATE)]
merged[,Good_match:=sum(is.na(LINKENDDT)),by=.(PERMCO,DATE)]
merged = merged[!(prob==TRUE & Good_match==TRUE & !is.na(LINKENDDT))]

# THIRD # 
# Use the link that's been around the longest # 
dates = as.data.table(merged$LINKENDDT) 
dates = dates[-which(is.na(dates))]
max(dates$V1) 
rm(dates)

merged[,prob:=.N>1,by=.(PERMCO,DATE)]
merged[,Good_match:=NULL]
merged[is.na(LINKENDDT),LINKENDDT:=as.Date('2022-01-31','%Y-%m-%d')]
merged[,Date_diff:=as.integer(LINKENDDT-LINKDT)]
setorder(merged,PERMCO,DATE,Date_diff)
merged[prob==TRUE,Good_match:=Date_diff==Date_diff[.N],by=.(PERMCO,DATE)]
merged = merged[!(prob==TRUE & Good_match!=TRUE)]

# FOURTH # 
# Use GVKEY that's been around the longest #
merged[,prob:=.N>1,by=.(PERMCO,DATE)]
merged[,Good_match:=NULL]
setorder(merged,GVKEY,LINKDT)
merged[prob==TRUE,start_Date:=LINKDT[1],by=.(GVKEY)]
setorder(merged,GVKEY,LINKENDDT)
merged[prob==TRUE,end_Date:=LINKENDDT[.N],by=.(GVKEY)]
merged[,Date_diff:=as.integer(end_Date-start_Date)]
setorder(merged,PERMCO,DATE,Date_diff)
merged[prob==TRUE,Good_match:=Date_diff==Date_diff[.N],by=.(PERMCO,DATE)]
merged = merged[!(prob==TRUE & Good_match!=TRUE)]

# FIFTH # 
setorder(merged,PERMCO,DATE,GVKEY)
merged = unique(merged,by=c('PERMCO','DATE'))

# CLEAN UP # 
if(nrow(unique(merged,by=c('GVKEY','DATE'))) !=nrow(merged) | nrow(unique(merged,by=c('PERMCO','DATE'))) !=nrow(merged)) {stop ('1. Monthly firm level returns.R: There is an issue with your merge between CRSP/Compustat')} 

mergedlink = copy(merged)
mergedlink[,LIID:=NULL]
mergedlink[,LINKDT:=NULL]
mergedlink[,LINKENDDT:=NULL]
mergedlink[,prob:=NULL]
mergedlink[,Date_diff:=NULL]
mergedlink[,start_Date:=NULL]
mergedlink[,end_Date:=NULL]
mergedlink[,Good_match:=NULL]
mergedlink[,special_key:=(mergedlink$Year+mergedlink$month/100)]

#============================================================================
#======================== IMPORT COMPUSTAT DATA =============================
#============================================================================

be_data = as.data.table(read_excel("Documents/Master/Master Thesis/Data_CRSP_Compustat/bm.xlsx"))
profitability = as.data.table(read_excel("Documents/Master/Master Thesis/Data_CRSP_Compustat/profitability.xlsx"))
investment = as.data.table(read_excel("Documents/Master/Master Thesis/Data_CRSP_Compustat/investment.xlsx"))

be_data$datadate = as.Date(be_data$datadate)
profitability$datadate = as.Date(profitability$datadate)
investment$datadate = as.Date(investment$datadate)

# Correct industry and data format # 
be_data <- be_data %>%
  filter(indfmt == 'INDL' & datafmt == 'STD') %>%
  select(-c(indfmt, datafmt))

profitability <- profitability %>%
  filter(indfmt == 'INDL' & datafmt == 'STD') %>%
  select(-c(indfmt, datafmt))

investment <- investment %>%
  filter(indfmt == 'INDL' & datafmt == 'STD') %>%
  select(-c(indfmt, datafmt))

# Keep only distinct observations # 
be_data = distinct(be_data)
profitability = distinct(profitability)
investment = distinct(investment)

# be_data[,Year:=year(datadate)]
# be_data[,month:=month(datadate)]
# be_data[,key:=paste(Year,month)]

#============================================================================
#============================================================================
#============================================================================

# MERGE COMPUSTAT DATA # 
compustat_merged = merge(be_data,investment,by.x = c('GVKEY','datadate'),by.y = c('GVKEY', 'datadate'),allow.cartesian = T)

compustat_merged[,fiscaldate.y:=NULL]
compustat_merged[,LIID.y:=NULL]
setnames(compustat_merged, 'fiscaldate.x', 'fiscaldate')
setnames(compustat_merged, 'LIID.x', 'LIID')

compustat = merge(compustat_merged, profitability, by.x = c('GVKEY','datadate'),by.y = c('GVKEY', 'datadate'),allow.cartesian = T)

compustat[,fiscaldate.y:=NULL]
compustat[,LIID.y:=NULL]
setnames(compustat, 'fiscaldate.x', 'fiscaldate')
setnames(compustat, 'LIID.x', 'LIID')

# CLEAN UP # 
compustat$expense[is.na(compustat$expense)] <- 0
compustat$interest[is.na(compustat$interest)] <- 0
compustat$rev[is.na(compustat$rev)] <- 0
compustat$cogs[is.na(compustat$cogs)] <- 0

rm(be_data, investment, profitability, compustat_merged)

compustat[,Year:=year(datadate)]
compustat[,month:=month(datadate)]
compustat[,key:=paste(Year,month)]

compustat[,special_key:=(compustat$Year+compustat$month/100)]

#============================================================================
#============================================================================
#============================================================================

# VARIABLE COMPUTATIONS # 

# SHAREHOLDERS'S EQUITY (SHE) # 
compustat[,SHE:=ifelse(!is.na(seq),seq,ifelse(!is.na(ceq+pstk),ceq+pstk,ifelse(!is.na(at+lt+mib),at-lt-mib,at-lt)))] 

# PREFERRED STOCK (PS) # 
compustat[,PS:=ifelse(!is.na(pstkrv),pstkrv,ifelse(!is.na(pstkl),pstkl,pstk))]

# BOOK EQUITY (BE) = Common Equity per definition # 
compustat[,BE:=SHE-PS]

# CLEAN UP # 
compustat = compustat[,at:=NULL]
compustat = compustat[,ceq:=NULL]
compustat = compustat[,lt:=NULL]
compustat = compustat[,mib:=NULL]
compustat = compustat[,pstk:=NULL]
compustat = compustat[,pstkl:=NULL]
compustat = compustat[,pstkrv:=NULL]
compustat = compustat[,seq:=NULL]

compustat = compustat[,SHE:=NULL]
compustat = compustat[,PS:=NULL]

# INVESTMENT (INV) # 
compustat[,assets_t_min_1:=shift(assets)]
compustat[,assets_t_min_2:=shift(assets_t_min_1)]
compustat[,INV:=(assets_t_min_2-assets_t_min_1)/assets_t_min_2]

# CLEAN UP # 
compustat = compustat[,assets:=NULL]
compustat = compustat[,assets_t_min_1:=NULL]
compustat = compustat[,assets_t_min_2:=NULL]

# PROFITABILITY (OP) # 
# compustat[,OP:=ifelse(!is.na(rev+cogs+expense+interest+lagged_BE_by_year),(rev-cogs-expense-interest)/lagged_BE_by_year,NA)]

# CLEAN UP # 
# compustat = compustat[,rev:=NULL]
# compustat = compustat[,cogs:=NULL]
# compustat = compustat[,expense:=NULL]
# compustat = compustat[,interest:=NULL]

#============================================================================
#============================================================================
#============================================================================

# MERGE CRSP AND COMPUSTAT DATA # 
CRSP_compustat = merge(mergedlink,compustat,by=c('GVKEY','key'),all.x=TRUE)

# CLEAN UP # 
CRSP_compustat[,Year.y:=NULL]
CRSP_compustat[,month.y:=NULL]
CRSP_compustat[,special_key.y:=NULL]
CRSP_compustat[,datadate:=NULL]
CRSP_compustat[,fiscaldate:=NULL]
CRSP_compustat[,LIID:=NULL]
CRSP_compustat[,PERMCO:=NULL]
CRSP_compustat[,PERMNO:=NULL]
CRSP_compustat[,Year:=NULL]
CRSP_compustat[,month:=NULL]

setnames(CRSP_compustat, 'special_key.x', 'special_key')

setorderv(CRSP_compustat,c("GVKEY","special_key"))

# CRSP_compustat = CRSP_compustat[,c("GVKEY","key","DATE","EXCHCD","MKTCAP","RET","Year","month","special_key","datadate","fiscaldate","BE")]

# Determine reference date for matching (i.e., June of next calendar year) #  
CRSP_compustat = CRSP_compustat[,reference_date:=paste0(year(DATE) + 1, "-06-01")]

#============================================================================
#========================== SIZE FORMED ON BM ===============================
#============================================================================

# CONSTRUCT STOCK SAMPLE # 

# Select relevant variables # 
stocks_BM <- CRSP_compustat %>%
  select(GVKEY, EXCHCD,DATE, RET, MKTCAP, BE, reference_date) %>%
  na.omit()

# Add ME data from the end of year t-1 which is used for BM ratio in June of year t # 
stocks_me <- stocks_BM %>% 
  filter(month(DATE) == 12) %>%
  mutate(reference_date = paste0(year(DATE) + 1, "-06-01")) %>%
  select(GVKEY, reference_date, DATE, me = MKTCAP)

# Merge BE and ME data 
stocks_BM = merge(stocks_BM,stocks_me,by.x = c('GVKEY','reference_date'),by.y = c('GVKEY', 'reference_date'), allow.cartesian = T)

# Clean up # 
stocks_BM[,DATE.y:=NULL]
setnames(stocks_BM, 'DATE.x', 'DATE')

# Multiply BE with 1000 to be consistent with ME data # 
stocks_BM$BE = stocks_BM$BE*1000

# Compute BM # 
stocks_BM$BM = stocks_BM$BE / stocks_BM$me

# Only keep stocks that have all the necessary data (i.e., me data for December t-1, and June t, and BE for t-1) # 
stocks_BM = na.omit(stocks_BM)

#============================================================================
#============================================================================
#============================================================================

# SIZE SORTING FOR SMB_BM # 

# In June of each year, all NYSE stocks are ranked on size to get the median # 
size_breakpoints <- stocks_BM %>% 
  filter(EXCHCD == 1) %>%
  select(reference_date, MKTCAP) %>%
  group_by(reference_date) %>%
  summarize(size_median = median(MKTCAP)) 

# Also in June, all stocks are sorted into two portfolios # 
size_sort <- stocks_BM %>%
  left_join(size_breakpoints, by = "reference_date") %>%
  mutate(size_portfolio = case_when(MKTCAP > size_median ~ "B",
                                    MKTCAP <= size_median ~ "S", 
                                    TRUE ~ as.character(NA))) %>%
  select(GVKEY, reference_date, size_portfolio)

# Add size portfolio assignment back to stock data # 
stocks_BM <- stocks_BM %>% 
  left_join(size_sort, by = c("GVKEY", "reference_date"))

#============================================================================
#============================================================================
#============================================================================

# VALUE SORTING # 

# Calculate value breakpoints using NYSE stocks # 
value_breakpoints <- stocks_BM %>% 
  filter(EXCHCD == 1) %>% 
  select(reference_date, BM) %>% 
  group_by(reference_date) %>% 
  summarize(value_q30 = quantile(BM, 0.3), 
            value_q70 = quantile(BM, 0.7))

# Also in June, all stocks are sorted into three portfolios 
value_sorts <- stocks_BM %>% 
  left_join(value_breakpoints, by = "reference_date") %>%
  mutate(value_portfolio = case_when(BM > value_q70 ~"V",
                                     BM <= value_q70 & BM > value_q30 ~ "N",
                                     BM <= value_q30 ~"G",
                                     TRUE ~ as.character(NA))) %>%
  select(GVKEY, reference_date, value_portfolio)

# Add value portfolio assignment back to stock data # 
stocks_BM <- stocks_BM %>% 
  left_join(value_sorts, by = c("GVKEY", "reference_date"))

#============================================================================
#============================================================================
#============================================================================

# CONSTRUCT FACTOR PORTOFLIOS # 

# SMB_BM_portfolios # 
SMB_BM_portfolios <- stocks_BM %>% 
  group_by(reference_date, size_portfolio, value_portfolio) %>% 
  summarize(ret_vw = weighted.mean(RET, MKTCAP)) %>% # NB: MKTCAP is the "weight" to get VW rets 
  ungroup() %>% 
  mutate(portfolio = paste0(size_portfolio, "/", value_portfolio))

factors_BM <- SMB_BM_portfolios %>%
  group_by(reference_date) %>%
  summarize(SMB_BM = mean(ret_vw[portfolio %in% c("S/V", "S/N", "S/G")]) - 
              mean(ret_vw[portfolio %in% c("B/V", "B/N", "B/G")]),
            HML = mean(ret_vw[portfolio %in% c("S/V", "B/V")]) - 
              mean(ret_vw[portfolio %in% c("S/G", "B/G")]))

#============================================================================
#========================== SIZE FORMED ON OP ===============================
#============================================================================

# CONSTRUCT STOCK SAMPLE # 

# Select relevant variables # 
stocks_OP <- CRSP_compustat %>%
  select(GVKEY, EXCHCD,DATE, RET, MKTCAP, BE, rev, cogs, interest, expense, reference_date) %>%
  na.omit()

# Add ME data from the end of year t-1 which is used for BM ratio in June of year t # 
stocks_me <- stocks_OP %>% 
  filter(month(DATE) == 12) %>%
  mutate(reference_date = paste0(year(DATE) + 1, "-06-01")) %>%
  select(GVKEY, reference_date, DATE, me = MKTCAP)

# Merge BE and ME data 
stocks_OP = merge(stocks_OP,stocks_me,by.x = c('GVKEY','reference_date'),by.y = c('GVKEY', 'reference_date'), allow.cartesian = T)

# Clean up # 
stocks_OP[,DATE.y:=NULL]
setnames(stocks_OP, 'DATE.x', 'DATE')

# Compute OP # 
stocks_OP[,OP:=ifelse(!is.na(rev+cogs+expense+interest),(rev-cogs-expense-interest)/BE,NA)]

stocks_OP[,rev:=NULL]
stocks_OP[,cogs:=NULL]
stocks_OP[,interest:=NULL]
stocks_OP[,expense:=NULL]
stocks_OP[,BE:=NULL]

# Only keep stocks that have all the necessary data (i.e., me data for December t-1, and June t, and BE for t-1) # 
stocks_BM = na.omit(stocks_BM)

#============================================================================
#============================================================================
#============================================================================

# SIZE SORTING FOR SMB_OP # 

# In June of each year, all NYSE stocks are ranked on size to get the median # 
size_breakpoints_OP <- stocks_OP %>% 
  filter(EXCHCD == 1) %>%
  select(reference_date, MKTCAP) %>%
  group_by(reference_date) %>%
  summarize(size_median = median(MKTCAP)) 

# Also in June, all stocks are sorted into two portfolios # 
size_sort_OP <- stocks_OP %>%
  left_join(size_breakpoints_OP, by = "reference_date") %>%
  mutate(size_portfolio = case_when(MKTCAP > size_median ~ "B",
                                    MKTCAP <= size_median ~ "S", 
                                    TRUE ~ as.character(NA))) %>%
  select(GVKEY, reference_date, size_portfolio)

# Add size portfolio assignment back to stock data # 
stocks_OP <- stocks_OP %>% 
  left_join(size_sort_OP, by = c("GVKEY", "reference_date"))

#============================================================================
#============================================================================
#============================================================================

# VALUE SORTING # 

# Calculate value breakpoints using NYSE stocks # 
value_breakpoints_OP <- stocks_OP %>% 
  filter(EXCHCD == 1) %>% 
  select(reference_date, OP) %>% 
  group_by(reference_date) %>% 
  summarize(value_q30 = quantile(OP, 0.3), 
            value_q70 = quantile(OP, 0.7))

# Also in June, all stocks are sorted into three portfolios 
value_sorts_OP <- stocks_OP %>% 
  left_join(value_breakpoints_OP, by = "reference_date") %>%
  mutate(profit_portfolio = case_when(OP > value_q70 ~"R",
                                     OP <= value_q70 & OP > value_q30 ~ "N",
                                     OP <= value_q30 ~"W",
                                     TRUE ~ as.character(NA))) %>%
  select(GVKEY, reference_date, profit_portfolio)

# Add value portfolio assignment back to stock data # 
stocks_OP <- stocks_OP %>% 
  left_join(value_sorts_OP, by = c("GVKEY", "reference_date"))

#============================================================================
#============================================================================
#============================================================================

# CONSTRUCT FACTOR PORTOFLIOS # 

# SMB_OP_portfolios # 
SMB_OP_portfolios <- stocks_OP %>% 
  group_by(reference_date, size_portfolio, profit_portfolio) %>% 
  summarize(ret_vw = weighted.mean(RET, MKTCAP)) %>% # NB: MKTCAP is the "weight" to get VW rets 
  ungroup() %>% 
  mutate(portfolio = paste0(size_portfolio, "/", profit_portfolio))

factors_OP <- SMB_OP_portfolios %>%
  group_by(reference_date) %>%
  summarize(SMB_OP = mean(ret_vw[portfolio %in% c("S/R", "S/N", "S/W")]) - 
              mean(ret_vw[portfolio %in% c("B/R", "B/N", "B/W")]),
            RMW = mean(ret_vw[portfolio %in% c("S/R", "B/R")]) - 
              mean(ret_vw[portfolio %in% c("S/W", "B/W")]))

#============================================================================
#============================================================================
#============================================================================

